{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.1 Kubernetes and TensorFlow Serving\n",
    "\n",
    "In this chapter we'll use TensorFlow serving for serving our clothing classification model. TF Serving is a special tool from the TF family which is specifically created for serving TF models. TF serving is a library that is written in C++, so it's very efficient but it also focuses on inference. You cannot do anything else with that library.\n",
    "\n",
    "How does it work?\n",
    "TF Serving gets a request with the X matrix which is the already prepared image. The result is a Numpy array with 10 predictions (in our case because of having 10 different classes). The user will not do the preprocessing, so we need something between the user and the TF Serving which is called gateway. A gateway gets an url, downloads the image, resizes it and turning into Numpy array, and pre-process it, and outputs predictions in a consumable format (f.e. json format). That means the gateway is also post-processing the output. The only thing the user needs to do is uploading the image to the website that uses the gateway. For implementing the gateway we'll use flask. Then we'll take the gateway and TF Serving and deploy it to Kubernetes.There is one benefit in using TF Serving. We can use GPU for applying the model. That means a lot of matrix multiplications.\n",
    "\n",
    "How this chapter is organized?\n",
    "- We'll take the model we trained already with Keras and convert it to a format that TF Serving expects which is called \"saved_model\" format.\n",
    "- We'll deploy this model locally with Docker and see how to interact with that.\n",
    "- After that we'll create this pre-processing service which we called gateway. We'll create two servers each of them will run in its own Docker container. We need to ensure that both can talk to each other\n",
    "- Then we'll talk about Docker-compose as a way of running two services that communicate with each other on one machine.\n",
    "- Then we'll look at the main concepts from Kubernetes.\n",
    "- After that we'll deploy a simple application to Kubernetes and set it up. Actually we'll run Kubernetes locally using a thing called Kind, which is a lightweight Kubernetes that you can run on your local machine.\n",
    "- Then we'll take the services that we created and deploy them to Kubernetes.\n",
    "- Finally we'll move these things from our local Kubernetes cluster to a cluster in the cloud. We'll use EKS which is a managed Kubernetes from AWS, but it should work for any cloud provider.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10.2 TensorFlow Serving\n",
    "## The saved_model format\n",
    "Here we'll use again the model which was trained for the book (xception_v4_large_08_0.894.h5). We can use wget again to download the model (and save it as clothing-model-v4.h5). Now we can convert the model from h5 format to the saved_model format. For the converting we only need a few lines of code. You can do this by using ipython."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-11-26 19:04:27.669289: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:04:27.857802: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-26 19:04:27.857866: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-26 19:04:27.860253: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-26 19:04:27.880153: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:04:27.881751: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-26 19:04:30.396286: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: clothing-model/assets\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "model = keras.models.load_model('./clothing-model-v4.h5')\n",
    "\n",
    "tf.saved_model.save(model, 'clothing-model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".:\n",
      "total 83M\n",
      "-rw-rw-r-- 1 peter peter    0 Nov  26 18:18 10-KubTFServing.ipynb\n",
      "drwxr-xr-x 4 peter peter 4,0K Nov  26 19:05 clothing-model\n",
      "-rw-rw-r-- 1 peter peter  83M Nov  26 19:03 clothing-model-v4.h5\n",
      "\n",
      "./clothing-model:\n",
      "total 2,3M\n",
      "drwxr-xr-x 2 peter peter 4,0K Nov  26 19:05 assets\n",
      "-rw-rw-r-- 1 peter peter   57 Nov  26 19:05 fingerprint.pb\n",
      "-rw-rw-r-- 1 peter peter 2,3M Nov  26 19:05 saved_model.pb\n",
      "drwxr-xr-x 2 peter peter 4,0K Nov  26 19:05 variables\n",
      "\n",
      "./clothing-model/assets:\n",
      "total 0\n",
      "\n",
      "./clothing-model/variables:\n",
      "total 83M\n",
      "-rw-rw-r-- 1 peter peter 83M Nov  26 19:05 variables.data-00000-of-00001\n",
      "-rw-rw-r-- 1 peter peter 15K Nov  26 19:05 variables.index\n"
     ]
    }
   ],
   "source": [
    "!ls -lhR"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can look what's inside the model using the utility saved_model_cli."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023-11-26 19:09:33.048917: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:09:33.246135: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2023-11-26 19:09:33.246206: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2023-11-26 19:09:33.250297: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2023-11-26 19:09:33.272191: I external/local_tsl/tsl/cuda/cudart_stub.cc:31] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-11-26 19:09:33.272700: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-11-26 19:09:35.453409: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n",
      "\n",
      "MetaGraphDef with tag-set: 'serve' contains the following SignatureDefs:\n",
      "\n",
      "signature_def['__saved_model_init_op']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['__saved_model_init_op'] tensor_info:\n",
      "        dtype: DT_INVALID\n",
      "        shape: unknown_rank\n",
      "        name: NoOp\n",
      "  Method name is: \n",
      "\n",
      "signature_def['serving_default']:\n",
      "  The given SavedModel SignatureDef contains the following input(s):\n",
      "    inputs['input_28'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 299, 299, 3)\n",
      "        name: serving_default_input_28:0\n",
      "  The given SavedModel SignatureDef contains the following output(s):\n",
      "    outputs['dense_22'] tensor_info:\n",
      "        dtype: DT_FLOAT\n",
      "        shape: (-1, 10)\n",
      "        name: StatefulPartitionedCall:0\n",
      "  Method name is: tensorflow/serving/predict\n",
      "The MetaGraph with tag set ['serve'] contains the following ops: {'ReadVariableOp', 'Identity', 'Conv2D', 'Placeholder', 'ShardedFilename', 'MatMul', 'RestoreV2', 'Pack', 'VarHandleOp', 'AssignVariableOp', 'DisableCopyOnRead', 'MergeV2Checkpoints', 'NoOp', 'SaveV2', 'Relu', 'AddV2', 'BiasAdd', 'DepthwiseConv2dNative', 'StringJoin', 'MaxPool', 'FusedBatchNormV3', 'StaticRegexFullMatch', 'StatefulPartitionedCall', 'Const', 'Mean', 'Select'}\n",
      "\n",
      "Concrete Functions:\n",
      "  Function Name: '__call__'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_28: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_28')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_28: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_28')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "\n",
      "  Function Name: '_default_save_signature'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_28: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_28')\n",
      "\n",
      "  Function Name: 'call_and_return_all_conditional_losses'\n",
      "    Option #1\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_28: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_28')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: False\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n",
      "    Option #2\n",
      "      Callable with:\n",
      "        Argument #1\n",
      "          input_28: TensorSpec(shape=(None, 299, 299, 3), dtype=tf.float32, name='input_28')\n",
      "        Argument #2\n",
      "          DType: bool\n",
      "          Value: True\n",
      "        Argument #3\n",
      "          DType: NoneType\n",
      "          Value: None\n"
     ]
    }
   ],
   "source": [
    "!saved_model_cli show --dir clothing-model --all"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "signature_def['serving_default']:\n",
    "  The given SavedModel SignatureDef contains the following input(s):\n",
    "    inputs['input_28'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 299, 299, 3)\n",
    "        name: serving_default_input_28:0\n",
    "  The given SavedModel SignatureDef contains the following output(s):\n",
    "    outputs['dense_22'] tensor_info:\n",
    "        dtype: DT_FLOAT\n",
    "        shape: (-1, 10)\n",
    "        name: StatefulPartitionedCall:0\n",
    "  Method name is: tensorflow/serving/predict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\"serving_default\" is the name of the signature definition. This is something technical but we need to know this value when we invoke our model.\n",
    "Then we have an input and an output. The input is called 'input_28'. The shape of input is 299x299x3 and -1 means that we have a batch of arbitrarily many images.\n",
    "The output is called 'dense_22'. The shape is 10 and -1 means again that we can have a lot of outputs.\n",
    "So what we need from this definition are the following information:\n",
    "- serving_default\n",
    "- input_28 - input\n",
    "- dense_22 - output"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Running TF-Serving locally with Docker\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can use this information to run TF-Serving locally with Docker. Just for repitition 8500:8500 means the local port 8500 is mapped to the port 8500 inside the container. For mounting\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!docker run -it --rm -p 8500:8500 -v \"./clothing-model:\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Invoking the model from Jupyter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
